# May 30, 2024

I've been meaning to document my work but just couldn't quite figure out the medium. I guess here is better than nowhere.

A recap for my first blog post.

## Getting started

I started out building an environment within GitHub Codespaces. This is part of a challenge. I am going to code the majority of this OS on my iPad.
After getting my hello world kernel up and running following the tutorial at wiki.osdev.org I got to work.

I spent a little bit of time going over Intel's official x86 documentation. One of the funniest things about x86 architecture is how segmentation is not optional
yet there is a model where to get it out of the way you simply set your segments to span the entire memory address space.

A key take away is that when an address is read or written the processor processes the segment information before it processes the page tables to figure out where that address actually exists.
This makes segments in my opinion redundant in the face of paging. Especially since paging can provide some of the same security features as segmentation.

## Coding practices

I want to take everything I've learned in the past 15+ years of coding to build a reliable OS. This meant building structs in C++ to make manipulating things like memory segements and pages stupid easy.
This also meant writing unit tests to make sure the code around these structs do what they're supposed to do.

Side note, the diagrams of 16+ byte data structures in the Intel documentation are sort of hard to interpret. I guess because it was written in a different time for a different type of programmer. I've
spent most of my time in C#, not having to worry about the order or fields in a byte array. This caused a lot of struggle in trying to get segments right but after switching the order of my 32-bit fields things worked.

I know Linux Torvalds LOVES plain C for Linux development but I picked C++ mostly because if I used C, I'm likely to get this wrong. The same goes for Rust of which I've never written anything outside of a hello world for.

Experience has told me that the abstractions I will be able to build in C++ for stuff may pay off in the long run for some interesting things.

## Memory Management

After messing around with the global descriptor table and starting on an interrupt descriptor table but not actually using it I have decided to build out my memory manager.

First thing is first was figuring out paging. Turning on paging is like switching coordinate systems. If you do it wrong your processor will start executing addresses that do not contain your code. If you do it right, it will be as if nothing happened and your kernel will continue to run. The trick with enabling paging is that you need to build a page table that maps the code you're currently running while maintaining the addresses that code is expected to be at.

Once I figured out paging, I dug around to try to see how other OS's might manage memory and in my usual TDLR fashion I decided to roll my own system completely from scratch. No buddy allocator for me.

Another side note, I acknowledge what I am trying to do has probably already been tried and there is probably a reason why it's not being used in the Linux kernel. That said... I honestly don't know
if how I plan on managing memory has ever been tried. I can't find any reference on the internet but then again I don't know what magical search terms would bring up this method.

The theory behind my first attempt at writing a memory allocator involves using x86's native page structures to keep track of what's allocated, but link all the free segments by size and address. In a sense,
free blocks are indexed by size and address. The theory is I can find blocks of a certain size or if I want blocks that are close to each other, for cache locality, I can use the address index. Since the index is inside of the free blocks
it takes up no additional memory. This would mean all of the overhead in managing memory is in the page tables. I do not know how well this will perform however compared to the other established memory allocators.

I'm really not great at binary trees but I gave it a try anyway to build my binary trees of free blocks. Things at first seemed to work. I'm a suspicious person because as I said I'm not great at binary search trees. So I wrote unit tests
to randomly allocate and deallocate blocks. At first things were fine with something like 10 - 100 allocations. But then I bumped up the random activity to 1,000 operations. That's when I started getting segmentation faults and program hangs.
Some order of operations were leading to free blocks linking to themselves.

I devised ways to record the exact operations allocating and deallocating so that I could turn that order of operations into a repeatable unit test.

After banging my head a bit I decided to take a break. I literally slept on it. Laying in bed trying to picture the binary tree and how I needed to physically manipulate it.
The problem with the way I was building my binary tree is that many algorithms sort of cheat in how they remove nodes. They have the luxury of swaping values of nodes inside of the tree rather than physically removing the nodes.
Because the size of a free block IS the value I do not have that luxury.

I finally pictured my binary tree as a bunch of nodes connected by strings. I imagined cutting the strings for the inner node and splicing them back together without that node.
From there I was able to derive a new algorithm and rewrite all my memory block management code. Suddenly my 1000 memory operation test started passing consistently. I had won.

In some ways this is a personal victory. I could never get binary trees right. It is satisfying to implement such a thing when during my day job I mostly move around bits of information.

Some cool things I want to do with my memory manager is come up with ways to defrag memory, for cache locality. In theory I can allocate pages for the purpose of moving existing pages around. The abstractions I build can make this trivial.

Checking my commit logs, it has taken me a month (some 30 hours in Codespace time) to figure out my memory manager.

## Application Loading

I'm finally at a point where I can start loading applications. One problem here is that I currently do not have persistent storage but we can work around that for now. I plan on building binaries and embedding them in my kernel image for now.

I began reading about the ELF format and ran into a big problem. There are ELF binaries that use absolute addresses.

So... about process memory. When a process needs to make a system call to the kernel, the processor is really only capable of jumping to priviledged code. It doesn't mess with page tables although it can change code segments. In practice you have to
map kernel code INTO the process space for that code to be available. You may even go as far as mapping kernel data structures into process space as well. Most operating systems reserve a portion of a process's address space for kernel code and data.

The implication of an ELF binary using absolute addresses is that the ELF binary can dictate where data and code segments are to be loaded into memory. This restricts WHERE kernel code and data can exist in a process's memory. The Linux kernel for example
is a "higher-half" kernel in that it maps the kernel at the upper portion of a process's address space.

I suspect my binaries are not relocatable. That is to say that if I arbitrarily map my kernel at the higher half of the address space it may not work right.
When my kernel needs to access some global data that was defined inside the binary, does it use a relative address or an absolute address?

I've Googled to see how the Linux kernel does all of this. There is some linker magic that you can potentially do to get things to work out but it requires paging is setup BEFORE the kernel logic is run. I don't fully understand the linker magic however.
The linker file specifies that the kernel code exist about 3 GB, but when the kernel is loaded with paging turned off, what does the boot loader do if there is only 1 GB of memory?

I guess in theory I can make my kernel "position independent" but there is a performance trade off here. Using the relocatable flag I suspect is only useful for the boot loader, which is GRUB in this case.

So how can we do this?

As of this writing the strategy I am going to employ is to refactor my kernel into parts. A kernel loader and the actual kernel. The kernel loader will handle memory setup and loading the kernel, with relocatable features.
This will allow for the kernel to exist anywhere I want it to without the performance hit position independent code will have. Another benefit is that when I get to building a file system driver, I can package in the loader and put the actual kernel in the file system.
New versions of the kernel can simply be installed in the file system without having to touch what was setup with GRUB.

So far as of this writing, I have split out my kernel-loader code into it's own project. Nothing has been tested, I need to go to bed.

Good night y'all!!!